{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gskKSeycfnuO"
   },
   "source": [
    "## Análisis exploratorio de datos\n",
    "\n",
    "A continuación se presenta un primer análisis basado en los datos del Censo INE 2011, publicados en la página web del Instituto.\n",
    "\n",
    "Además se utilizan varios conjuntos de datos disponibilizados en la web. Se realizó un pre-procesamiento para seleccionar variables relevantes, reduciendo el volúmen de datos y por tanto los requerimientos informáticos para su acceso. Las capas de información geográfica comprenden los de polígonos de departamentos y los puntos correspondientes a las localidades del INE, identificando las capitales departamentales en esta última capa.\n",
    "\n",
    "También se cuenta con una matriz de distancias entre cada centro medio de población, calculada con la API Google Distance Matrix, que consta de distancias a pie por la red de caminería entre el centro medio de población de cada departamento, obteniendo una matriz de 342 valores ((19x19)-19).\n",
    "\n",
    "Se prefirió usar el centro medio de población, en detrimento del centroide o la capital departamental. El centro medio de población se calcula transfiriendo el conteo de habitantes del segmento censal al centroide de dicho segmento, aplicando luego la siguiente fórmula:\n",
    "\n",
    "$$\n",
    "\\overline{X}_w=\\frac{\\sum_{i=1}^{n}w_{i}X_{i}}{\\sum_{i=1}^{n} w_{i}}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\overline{Y}_w=\\frac{\\sum_{i=1}^{n}w_{i}Y_{i}}{\\sum_{i=1}^{n} w_{i}}\n",
    "$$\n",
    "\n",
    "dónde\n",
    "\n",
    "$$w = peso$$\n",
    "\n",
    "En este caso el \"peso\" (w) sería la población, en tanto que \"x\" e \"y\" son las coordenadas cartográficas de cada centroide. De esta forma se obtiene un par de coordenadas para cada departamento, que representa ese centro medio.\n",
    "\n",
    "El uso del centro medio de población es más adecuado que usar el centroide en particular en aquellos departamentos en los cuales gran parte de la población se localiza concentrada en alguna ciudad lejana al centro del departamento. Los ejemplos paradigmáticos son Maldonado, Salto y Paysandú. En el caso contrario, es decir departamentos donde existe mayor dispesión espacial de la población, el centro medio de población se acerca más al centroide, en tanto que usar la capital sería no dar cuenta de la mencionada dispesión. Ejemplos de este caso son Colonia y Rocha. Es así que el centro medio de población proporciona una alternativa viable para contemplar estas dos categorías de departamentos.\n",
    "\n",
    "El PBI departamental de toma de la información producida y publicada por OPP **(cita).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "eIjjW8B2nubF",
    "outputId": "75594d27-744f-40cd-b135-c9763a5d990e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import tabulate\n",
    "from operator import add\n",
    "\n",
    "from shapely import wkt\n",
    "from shapely.geometry import shape, LineString, Point\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "    \n",
    "# funciones desarrolladas\n",
    "from functions.agrupar_dfs_censo import *\n",
    "from functions.graficas import get_bottoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "3CLV2-_7-DX1",
    "outputId": "f03f427b-1cc0-4b43-b861-2983f08bb38d"
   },
   "outputs": [],
   "source": [
    "# carga datos\n",
    "\n",
    "# Datos censales\n",
    "censo = pd.read_csv('tablas/personas_censo_2011.gz', compression='gzip', header=0, sep=',', quotechar='\"')\n",
    "# reemplaza el valor 5555 en edad (variable PERNA01) por NaNs\n",
    "censo.loc[censo.PERNA01 == 5555, 'PERNA01'] = np.nan\n",
    "\n",
    "# PBI departamental\n",
    "pbi = pd.read_csv('tablas/pbi_departamental.csv')\n",
    "\n",
    "# matriz de distancias\n",
    "md = pd.read_csv('tablas/df_distancias_centro_poblacion.csv')\n",
    "md.drop(['latlon_ori', 'latlon_des'], axis=1, inplace=True)\n",
    "\n",
    "# carga capa departamentos INE pg\n",
    "deptos = gpd.read_file('capas/ine_deptos.gpkg')\n",
    "\n",
    "# agrega centroides de departamentos\n",
    "deptos['centroide'] = deptos['geometry'].centroid\n",
    "\n",
    "# carga capa localidades INE pt\n",
    "localidad = gpd.read_file('capas/ine_localidades.gpkg')\n",
    "localidad.CODLOC = localidad.CODLOC.astype(int)\n",
    "\n",
    "# centro de población\n",
    "centro_pobl = gpd.read_file('capas/centro_poblacion.gpkg')\n",
    "\n",
    "# filtra capitales departamentales de las localidades INE\n",
    "capital = localidad[localidad.CAPITAL==True].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "censo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reclasificaciones de las variables de educación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reclas_edu_censo(df, old_var, new_var):\n",
    "    \"Reclasifica variables de educación en el Censo INE 2011\"\n",
    "    df.loc[df[old_var].between(1, 3),   new_var] = 1\n",
    "    df.loc[df[old_var].between(4, 5),   new_var] = 2\n",
    "    df.loc[df[old_var].between(6, 7),   new_var] = 3\n",
    "    df.loc[df[old_var].between(8, 10),  new_var] = 4\n",
    "    df.loc[df[old_var].between(11, 12), new_var] = 5\n",
    "    return df\n",
    "\n",
    "censo = reclas_edu_censo(censo, 'PERED03_R', 'PERED03_R_reclass')\n",
    "\n",
    "# cat 1: Preescolar, Primaria común. Primaria especial\n",
    "# cat 2: Ciclo Básico Liceo (1ero a 3ro), Ciclo Básico UTU (1ero a 3ro)\n",
    "# cat 3: Bachillerato Secundario (4to a 6to), Bachillerato UTU (4to a 6to)\n",
    "# cat 4: Enseñanza Técnica/Formación Profesional UTU, Magisterio o Profesorado, Terciario no universitario\n",
    "# cat 5: Universidad o Instituto Universitario (Carrera de grado o Licenciatura), Posgrado (Diploma/Maestría/Doctorado)\n",
    "\n",
    "# para verificar\n",
    "pd.DataFrame(censo.groupby(['PERED03_R', 'PERED03_R_reclass']).size()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# completa los valores faltantes (88) de la variable PERED03_1 con los \n",
    "# de la variable PERED03_2... Ésta última serían datos relevados en planillas (papel?)\n",
    "censo.loc[(censo.PERED03_1 == 88), 'PERED03_1'] = censo.PERED03_2\n",
    "\n",
    "# reclasifica\n",
    "censo = reclas_edu_censo(censo, 'PERED03_1', 'PERED03_1_reclass')\n",
    "\n",
    "# verifica\n",
    "pd.DataFrame(censo.groupby(['PERED03_1', 'PERED03_1_reclass']).size()).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dada la menor complejidad, se comienza por el análisis de los flujos entre departamentos.\n",
    "La base de personas del Censo INE 2011 se filtra según el siguiente criterio:\n",
    "- Variable \"PERMI07\" (lugar de residencia 5 años antes) con valores:\n",
    "    - 2 = en otra localidad o paraje de este departamento\n",
    "    - 3 = en otro departamento\n",
    "    \n",
    "Se excluyen habitantes de localidades rurales.\n",
    "\n",
    "La tabla resultante contiene un departamento de origen, uno de destino y una cantidad de personas que declaran haber vivido antes en el departamento de \"origen\", habiendo sido relevadas en el departamento de \"destino\" al momento de la aplicación del formulario censal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El perfil de la migración interna\n",
    "\n",
    "En el apartado 2.4, referido a los antecedentes del estudio de la migración interna en Uruguay, ya se puntualizaban algunas características de la población migrante interna:\n",
    "\n",
    "- el perfil más joven y feminizado de quienes migran hacia Montevideo.\n",
    "\n",
    "- el perfil de familias completas, integradas por parejas de entre 30 y 40 años con niños, de quienes migran desde Montevideo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# un primer análisis abarcando sólo aquellas personas que han migrado entre departamentos\n",
    "# (no toma en cuenta quienes han migrado otras localidades dentro del mismo departamento)\n",
    "mgr_interdep = censo.loc[censo.PERMI07 == 3].reset_index(drop=True)\n",
    "print(mgr_interdep.shape)\n",
    "\n",
    "mgr_interdep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Índice de masculinidad\n",
    "def indice_mascul(df, var_sexo):\n",
    "    \"Función para calcular índice de masculinidad sobre datos de personas del Censo INE 2011\"\n",
    "    # filtra varones y mujeres\n",
    "    varones = df.loc[df[var_sexo] ==1].count()[0] \n",
    "    mujeres = df.loc[df[var_sexo] ==2].count()[0]\n",
    "    # calcula el índice\n",
    "    ind_masc = (varones/mujeres)*100\n",
    "    \n",
    "    return round(ind_masc, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# según el censo 2011 el índice de masculinidad para todo el país es de:\n",
    "ind_m_pais = indice_mascul(censo, 'PERPH02')\n",
    "\n",
    "printmd(\"\"\"\n",
    "Según el censo 2011 el índice de masculinidad para todo el país es de **{}** hombres por cada 100 mujeres.\n",
    "\"\"\".format(ind_m_pais))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# índice de masculinidad para migrantes recientes\n",
    "ind_m_migr = indice_mascul(mgr_interdep, 'PERPH02')\n",
    "\n",
    "printmd(\"\"\"\n",
    "El índice de masculinidad para el conjunto de **migrantes recientes** es de **{}** hombres por cada 100 mujeres.\n",
    "\"\"\".format(ind_m_migr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambia tipo de variable edad a número entero\n",
    "# mgr_interdep.PERNA01 = mgr_interdep.PERNA01.astype(int)\n",
    "\n",
    "# identifica depto de residencia anterior\n",
    "mgr_interdep['depto_origen'] = mgr_interdep.loc[:,('PERMI07_2')]\n",
    "mgr_interdep.depto_origen.fillna(mgr_interdep.DPTO, inplace=True)\n",
    "\n",
    "# # convierte a integer\n",
    "mgr_interdep.loc[:,('depto_origen')] = mgr_interdep.loc[:,('depto_origen')].astype(int)\n",
    "\n",
    "# # renombra DPTO\n",
    "mgr_interdep.rename(columns={'DPTO': 'depto_destino'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genera tres data frames con:\n",
    "- Migrantes de interior a Montevideo (A)\n",
    "- Migrantes de Montevideo a interior (B)\n",
    "- Migrantes entres deptos del interior (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genera dataframes por tipología\n",
    "def filter_df_mig(df, ver_dep_ori, var_dep_des):\n",
    "    \"Corta DFs según origen y destino de la migración\"\n",
    "    # destino Mvdeo.\n",
    "    a = df[df[var_dep_des] == 1].reset_index()\n",
    "    # origen Mvdeo. y destino no Mvdeo.\n",
    "    b = df[(df[ver_dep_ori] == 1) & (df[var_dep_des] != 1)].reset_index()\n",
    "    # origen y destino no Mvdeo.\n",
    "    c = df[(df[ver_dep_ori] != 1) & (df[var_dep_des] != 1)].reset_index()\n",
    "    \n",
    "    return a, b, c\n",
    "\n",
    "# aplica función\n",
    "a, b, c = filter_df_mig(mgr_interdep, 'depto_origen', 'depto_destino')\n",
    "\n",
    "# enlista los tres DFs\n",
    "lista_dfs = [a, b, c]\n",
    "len(lista_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Índice de masculinidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# índice de masculinidad para migrantes recientes que migran hacia Mvdeo.\n",
    "ind_m_desagregado = [indice_mascul(x, 'PERPH02') for x in lista_dfs]\n",
    "\n",
    "parte1 = \"El índice de masculinidad para el conjunto de migrantes recientes \"\n",
    "parte2 =  \" hombres por cada 100 mujeres.\"\n",
    "\n",
    "printmd(parte1 + \"**migrantes recientes hacia Montevideo** es de **{}**\"\"\".format(ind_m_desagregado[0]) + parte2)\n",
    "\n",
    "printmd(parte1 + \"**migrantes recientes desde Montevideo hacia el Interior** es de **{}**\"\"\".format(ind_m_desagregado[1]) + parte2)\n",
    "\n",
    "printmd(parte1 + \"**entre departamentos del interior** es de **{}**\"\"\".format(ind_m_desagregado[2]) + parte2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafica índices de maculinidad de cada población\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# ancho de las barras\n",
    "bars_width=0.4\n",
    "\n",
    "# ubicación de los grupos\n",
    "ind = np.arange(3)\n",
    "\n",
    "# límite en eje Y\n",
    "plt.ylim(0, 120)\n",
    "\n",
    "# colores\n",
    "color = 'darkcyan'\n",
    "\n",
    "# etiquetas\n",
    "labels = ['Hacia \\n Montevideo',\n",
    "          'Desde Montevideo \\n al interior',\n",
    "          'Entre departamentos \\n del interior']\n",
    "\n",
    "# plotea\n",
    "[plt.bar(i, ind_m_desagregado[i],  width=bars_width, color=color, label=labels[i]) for i in range(3)]\n",
    "\n",
    "# línea de mediana país\n",
    "plt.axhline(ind_m_pais, color='k')\n",
    "\n",
    "# agrega texto sobre el valor para todo el país\n",
    "ax.text(-0.2, ind_m_pais * 1.05, 'Valor para el país')\n",
    "\n",
    "# oculta ejes superior y derecho\n",
    "[ax.spines[x].set_visible(False) for x in [\"top\", \"right\"]]\n",
    "\n",
    "# oculta ticks y labels del eje X\n",
    "# ax.axes.get_xaxis().set_visible(False)\n",
    "\n",
    "# etiquetas en eje X\n",
    "plt.xticks(ind, labels)\n",
    "\n",
    "# oculta ticks en eje x\n",
    "plt.tick_params(axis='x', bottom=False, labelbottom=True) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genera lista de DFs a, b y c juntos con el Censo en el índice 0.\n",
    "lista_dfs_censo = lista_dfs.copy()\n",
    "lista_dfs_censo.insert(0, censo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proporción varones/mujeres\n",
    "def porcentaje_sexo(df, var_sexo):\n",
    "    \"Calcula el porcentaje por sexo de un dataframe\"\n",
    "    # filtra varones y mujeres\n",
    "    varones_prop = (df.loc[df[var_sexo] ==1].count()[0])/df.shape[0]*100\n",
    "    mujeres_prop = (df.loc[df[var_sexo] ==2].count()[0])/df.shape[0]*100\n",
    "\n",
    "    return (varones_prop, mujeres_prop)\n",
    "\n",
    "# aplica función para lista extendida de DFs\n",
    "prop_sexo_dfs = [porcentaje_sexo(x, 'PERPH02') for x in lista_dfs_censo]\n",
    "\n",
    "# traspone las listas\n",
    "prop_sexo_tranposed = [[h,i,j,k] for h,i,j,k in zip(*prop_sexo_dfs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "labels_extended = ['Total país',\n",
    "                   'Hacia \\n Montevideo',\n",
    "                   'Desde Montevideo \\n al interior',\n",
    "                   'Entre dptos. \\n del interior']\n",
    "\n",
    "\n",
    "# setea paleta de colores\n",
    "colors = 'skyblue', 'seagreen'\n",
    "\n",
    "# mínimo y máximo de ejes\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# controla el intervalo de etiquetas en los ticks del eje Y\n",
    "plt.yticks(np.arange(0, 101, 50))\n",
    "\n",
    "# n de barras\n",
    "ind=np.arange(4)\n",
    "\n",
    "_bottoms = [None, prop_sexo_tranposed[0]]\n",
    "\n",
    "# grafica\n",
    "p = [plt.bar(ind, prop_sexo_tranposed[i], width=bars_width, bottom=_bottoms[i], color=colors[i]) for i in range(2)]\n",
    "\n",
    "# oculta spines\n",
    "[ax.spines[x].set_visible(False) for x in [\"top\", \"right\"]]\n",
    "\n",
    "# labels\n",
    "plt.xticks(ind, labels_extended)\n",
    "\n",
    "# oculta ticks en eje x\n",
    "plt.tick_params(axis='x', bottom=False, labelbottom=True) \n",
    "\n",
    "# leyenda\n",
    "plt.legend(['Varones', 'Mujeres'],\n",
    "           bbox_to_anchor=(1.3, 1),\n",
    "           loc='upper right',\n",
    "           frameon=False,\n",
    "           labelspacing=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edades medianas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edades medianas\n",
    "emed = [x.PERNA01.median().astype(int) for x in lista_dfs]\n",
    "e_med_censo = censo.PERNA01.median().astype(int)\n",
    "\n",
    "printmd(\"\"\"Las edades medianas son **{}**, **{}** y **{}** años respectivamente. En tanto el valor para el país es de **{}**.\n",
    "\"\"\".format(emed[0], emed[1], emed[2], e_med_censo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafica edades medianas\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# n de barras\n",
    "ind=np.arange(3)\n",
    "\n",
    "# límite en eje Y\n",
    "plt.ylim(0, 40)\n",
    "\n",
    "# controla el intervalo de etiquetas en los ticks del eje Y\n",
    "plt.yticks(np.arange(0, 41, 10))\n",
    "\n",
    "# plotea\n",
    "[plt.bar(i, emed[i],  width=bars_width, color=color, label=labels[i]) for i in range(3)]\n",
    "\n",
    "# línea de mediana país\n",
    "plt.axhline(e_med_censo, color='k')\n",
    "\n",
    "# agrega texto sobre el valor para todo el país\n",
    "ax.text(-0.2, e_med_censo * 1.05, 'Valor para el país')\n",
    "\n",
    "# oculta spines superior y derecho\n",
    "[ax.spines[x].set_visible(False) for x in [\"top\", \"right\"]]\n",
    "\n",
    "# etiquetas en eje X\n",
    "plt.xticks(ind, labels)\n",
    "\n",
    "# oculta ticks en eje x\n",
    "plt.tick_params(axis='x', bottom=False, labelbottom=True) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Menores de 15 años"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menores de 15 años\n",
    "a_men_15, b_men_15, c_men_15 = [x.loc[(x.PERNA01 < 15)].shape[0] for x in lista_dfs]\n",
    "a_men_15_per, b_men_15_per, c_men_15_per = [round(x.loc[(x.PERNA01 < 15)].shape[0]/x.shape[0]*100,1) for x in lista_dfs]\n",
    "\n",
    "printmd('Menores de 15 años en mig. recientes hacia Mvdeo.: **{}**, correspondientes al **{} %**'.format(a_men_15, a_men_15_per))\n",
    "\n",
    "printmd('Menores de 15 años en mig. recientes hacia el interior: **{}**, correspondientes al **{} %**'.format(b_men_15, b_men_15_per))\n",
    "\n",
    "printmd('Menores de 15 años en mig. recientes entre deptos. del interior: **{}**, correspondientes al **{} %**'.format(c_men_15, c_men_15_per))\n",
    "\n",
    "# porcentaje para el total de datos del censo\n",
    "menores_15 = censo.loc[(censo.PERNA01 < 15)].shape[0]\n",
    "censo_men_15_per = round(menores_15 / censo.shape[0]*100,1)\n",
    "\n",
    "printmd('Menores de 15 años para todo el país: **{}**, correspondientes al **{} %**'.format(menores_15, censo_men_15_per))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribución por edades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agrupa datos\n",
    "edades_censo = agrupar_por_edades(censo, 'PERNA01')\n",
    "\n",
    "edades = [agrupar_por_edades(x, 'PERNA01') for x in lista_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploteo de edades\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "colors = ['firebrick', 'darkcyan', 'darkmagenta']\n",
    "\n",
    "[plt.plot(edades[i].edad, edades[i].porc_pers, color=colors[i], label=labels[i], linewidth=2) for i in range(3)]\n",
    "\n",
    "plt.plot(edades_censo.edad,\n",
    "         edades_censo.porc_pers,\n",
    "         label='Todas las personas',\n",
    "         linewidth=1,\n",
    "         color='k',\n",
    "         alpha=0.6)\n",
    "\n",
    "[ax.spines[x].set_visible(False) for x in [\"top\", \"right\"]]\n",
    "\n",
    "plt.legend( loc='upper right', frameon=False, labelspacing=1)\n",
    "\n",
    "# setea límites de ejex x e y\n",
    "plt.ylim(0, 10)\n",
    "plt.xlim(0, 80)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribución por grupos de edad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grupos_edad = [grupos_de_edad(x, 'PERNA01')  for x in lista_dfs_censo]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traspone las series enlistada y las devuelve en una lista \n",
    "grupos_edad_t = [[h,i,j,k] for h,i,j,k in zip(*grupos_edad)]\n",
    "grupos_edad_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# n de barras\n",
    "ind = np.arange(4)\n",
    "\n",
    "# setea paleta de colores\n",
    "colors = 'tab:olive', 'tab:cyan', 'tab:purple', 'silver'\n",
    "\n",
    "# mínimo y máximo de ejes\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# enlista los fondos calculados con la función get_bottoms\n",
    "_bottoms = get_bottoms(grupos_edad_t)\n",
    "\n",
    "# grafica\n",
    "p = [plt.bar(ind, grupos_edad_t[i], width=bars_width, color=colors[i], bottom=_bottoms[i]) for i in range(4)]\n",
    "\n",
    "# oculta spines\n",
    "[ax.spines[x].set_visible(False) for x in [\"top\", \"right\"]]\n",
    "\n",
    "# labels\n",
    "plt.xticks(ind, labels_extended)\n",
    "\n",
    "_labels = ['0 a 3 años',\n",
    "           '4 a 17 años',\n",
    "           '18 a 64 años',\n",
    "           '65 o más años']\n",
    "\n",
    "# oculta ticks en eje x\n",
    "plt.tick_params(axis='x', bottom=False, labelbottom=True) \n",
    "\n",
    "# leyenda\n",
    "plt.legend((p[0], p[1], p[2], p[3]),\n",
    "           _labels,\n",
    "           bbox_to_anchor=(1.45, 1),\n",
    "           loc='upper right',\n",
    "           frameon=False,\n",
    "           labelspacing=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Educación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edu_asist(df, var_edu):\n",
    "    \"Calcula los porcentajes de personas que asisten a centros educativos\"\n",
    "    df_filtered = df.loc[df[var_edu].between(1, 4), var_edu]\n",
    "    values = df_filtered.value_counts(normalize=True,sort=False).mul(100)\n",
    "    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplica a la lista de 4 DFs\n",
    "edu_asist = [get_edu_asist(x, 'PERED01') for x in lista_dfs_censo]\n",
    "\n",
    "# traspone las series enlistada y las devuelve en una lista \n",
    "edu_asist_list = [[h,i,j,k] for h,i,j,k in zip(*edu_asist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# n de barras\n",
    "ind = np.arange(4)\n",
    "\n",
    "# setea paleta de colores\n",
    "colors = 'tab:olive', 'tab:cyan', 'tab:purple', 'silver'\n",
    "\n",
    "# mínimo y máximo de ejes\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# enlista los fondos calculados con la función get_bottoms\n",
    "_bottoms = get_bottoms(edu_asist_list)\n",
    "\n",
    "# grafica\n",
    "p = [plt.bar(ind, edu_asist_list[i], width=bars_width, color=colors[i], bottom=_bottoms[i]) for i in range(4)]\n",
    "\n",
    "# oculta spines\n",
    "[ax.spines[x].set_visible(False) for x in [\"top\", \"right\"]]\n",
    "\n",
    "# labels\n",
    "plt.xticks(ind, labels_extended)\n",
    "\n",
    "_labels = ['Sí, a un establecimiento público',\n",
    "           'Sí, a un establecimiento privado',\n",
    "           'No asiste pero asistió',\n",
    "           'Nunca asistió']\n",
    "\n",
    "# oculta ticks en eje x\n",
    "plt.tick_params(axis='x', bottom=False, labelbottom=True) \n",
    "\n",
    "# leyenda\n",
    "plt.legend((p[0], p[1], p[2], p[3]),\n",
    "           _labels,\n",
    "           bbox_to_anchor=(1.65, 1),\n",
    "           loc='upper right',\n",
    "           frameon=False,\n",
    "           labelspacing=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Nivel educativo que cursa actualmente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edunivel = [x.PERED03_R_reclass.value_counts(normalize=True,sort=False).mul(100).sort_index()  for x in lista_dfs_censo]\n",
    "\n",
    "# enlista\n",
    "edunivel_list = [[h,i,j,k] for h,i,j,k in zip(*edunivel)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edunivel[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# ubicación de los grupos\n",
    "ind = np.arange(4)\n",
    "\n",
    "# mínimo y máximo de ejes\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# setea paleta de colores\n",
    "colors = 'tab:olive', 'tab:cyan', 'grey', 'tomato','indigo'\n",
    "\n",
    "# pairwise sum para completar los \"bottom\"\n",
    "_bottoms = get_bottoms(edunivel_list)\n",
    "\n",
    "# grafica\n",
    "p = [plt.bar(ind, edunivel_list[i], width=bars_width, color=colors[i], bottom=_bottoms[i]) for i in range(5)]\n",
    "\n",
    "# oculta spines\n",
    "[ax.spines[x].set_visible(False) for x in [\"top\", \"right\"]]\n",
    "\n",
    "# labels\n",
    "plt.xticks(ind, labels_extended)\n",
    "\n",
    "_labels = ['Primaria o prescolar',\n",
    "           'Ciclo básico (liceo o UTU)',\n",
    "           'Bachillerato (liceo o UTU)',\n",
    "           'Terciario no universitario',\n",
    "           'Universitario o posgrado']\n",
    "\n",
    "# oculta ticks en eje x\n",
    "plt.tick_params(axis='x', bottom=False, labelbottom=True) \n",
    "\n",
    "# leyenda\n",
    "plt.legend((p[0], p[1], p[2], p[3], p[4]),\n",
    "           _labels,\n",
    "           bbox_to_anchor=(1.65, 1),\n",
    "           loc='upper right',\n",
    "           frameon=False,\n",
    "           labelspacing=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Nivel más alto cursado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_edunivel = [x.PERED03_1_reclass.value_counts(normalize=True,sort=False).mul(100).sort_index()  for x in lista_dfs_censo]\n",
    "\n",
    "# enlista\n",
    "max_edunivel_list = [[h,i,j,k] for h,i,j,k in zip(*max_edunivel)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ind = np.arange(4)\n",
    "\n",
    "# pairwise sum para completar los \"bottom\"\n",
    "_bottoms = get_bottoms(max_edunivel_list)\n",
    "\n",
    "# mínimo y máximo de ejes\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# grafica\n",
    "p = [plt.bar(ind, max_edunivel_list[i], width=bars_width, color=colors[i], bottom=_bottoms[i]) for i in range(5)]\n",
    "\n",
    "# oculta spines\n",
    "[ax.spines[x].set_visible(False) for x in [\"top\", \"right\"]]\n",
    "\n",
    "# labels\n",
    "plt.xticks(ind, labels_extended)\n",
    "\n",
    "_labels = ['Primaria o prescolar',\n",
    "           'Ciclo básico (liceo o UTU)',\n",
    "           'Bachillerato (liceo o UTU)',\n",
    "           'Terciario no universitario',\n",
    "           'Universitario o posgrado']\n",
    "\n",
    "# oculta ticks en eje x\n",
    "plt.tick_params(axis='x', bottom=False, labelbottom=True) \n",
    "\n",
    "# leyenda\n",
    "plt.legend((p[0], p[1], p[2], p[3], p[4]),\n",
    "           _labels,\n",
    "           bbox_to_anchor=(1.65, 1),\n",
    "           loc='upper right',\n",
    "           frameon=False,\n",
    "           labelspacing=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.loc[a['PERNA01'].between(0,   14),  'grupo_edad'] = 1\n",
    "a.loc[a['PERNA01'].between(15, 64),  'grupo_edad'] = 2\n",
    "a.loc[a['PERNA01'] > 64,  'grupo_edad'] = 3\n",
    "a_group = a.groupby(['grupo_edad']).size().reset_index()\n",
    "\n",
    "# renombra vars\n",
    "a_group.rename(columns={0:'personas'}, inplace=True)\n",
    "# calcula porcentajes\n",
    "a_group['porc_pers'] = (a_group.personas / a_group.personas.sum())*100\n",
    "\n",
    "return a_group.porc_pers.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "p04HSl9Aa0tb",
    "outputId": "41934c34-bc0d-4ebc-9280-7e1591817bcd"
   },
   "outputs": [],
   "source": [
    "# # define columnas para filtrar\n",
    "# cols = ['DPTO', 'LOC', 'SECC', 'SEGM', 'PERMI07', 'PERMI07_1',\n",
    "#         'PERMI07_2', 'PERMI07_3', 'PERMI07_4']\n",
    "\n",
    "# # filtra\n",
    "# p_migr = censo.loc[(censo.PERMI07 == 2) | (censo.PERMI07 == 3), cols]\n",
    "\n",
    "# # cambia DPTO a tipo entero\n",
    "# p_migr.DPTO = p_migr.DPTO.astype(int)\n",
    "\n",
    "# # print(p_migr.shape[0])\n",
    "\n",
    "# # Hay 26.449 residentes en localidades rurales\n",
    "# # print(p_migr[( p_migr.LOC == 900 )].shape[0])\n",
    "\n",
    "# # identifica depto de residencia anterior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot de las capas de departamentos y localidades\n",
    "f, ax = plt.subplots(1,figsize=(8,6))\n",
    "\n",
    "# apaga ejes\n",
    "plt.axis('off')\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.get_xaxis().set_visible(False)\n",
    "\n",
    "# deptos\n",
    "deptos.plot(color='w', edgecolor='silver',ax=ax)\n",
    "\n",
    "# localidades\n",
    "centro_pobl.plot(markersize=12, color = 'red', ax = ax, label='Centro medio de población')\n",
    "deptos.geometry.centroid.plot(markersize=4, color = 'silver', ax = ax, label='Centroide')\n",
    "capital.plot(markersize=7, color = 'orange', ax = ax, label='Capital departamental')\n",
    "\n",
    "# título\n",
    "# pl.title(\"Centroide, centro de población y capitales departamentales\", size=10)\n",
    "\n",
    "# referencias\n",
    "plt.legend(fontsize=9, frameon=False)\n",
    "\n",
    "metadatos_figs = {'Author': '''Guillermo D'Angelo''', 'Title': 'Mapa Centro de Población'}\n",
    "\n",
    "# plt.savefig('mapas_graficas/centro_poblacion.pdf', bbox_inches='tight',\n",
    "#             metadata = metadatos_figs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "BPugrUOVjHi6",
    "outputId": "e141867c-3e13-436b-ec09-9dad9666d008"
   },
   "outputs": [],
   "source": [
    "# genera un sólo dataframe solo para deptos\n",
    "flujos_deptos = p_migr[['depto_origen', 'depto_destino']]\n",
    "\n",
    "flujos_deptos = flujos_deptos[flujos_deptos.depto_origen != flujos_deptos.depto_destino]\n",
    "\n",
    "flujos_deptos['personas_mig'] = 1\n",
    "\n",
    "# agrupa y cuenta\n",
    "grupo = flujos_deptos.groupby(by=['depto_origen', 'depto_destino']).sum()\n",
    "\n",
    "print('Cantidad de díadas ', grupo.shape[0])\n",
    "\n",
    "grupo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grupo.reset_index().head().to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se presentan dichos datos en formato de matriz simétrica, refiriéndose a cada departamento con su código INE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "colab_type": "code",
    "id": "qwpxiO0oh3T2",
    "outputId": "ce6fb4a5-c248-45cb-8b13-205797d672c4"
   },
   "outputs": [],
   "source": [
    "# genera tabla pivot con los flujos de departamento a departamento\n",
    "matrix = pd.pivot_table(flujos_deptos,\n",
    "                        index ='depto_origen',\n",
    "                        columns='depto_destino',\n",
    "                        fill_value=0,\n",
    "                        aggfunc=sum,\n",
    "                        margins=True,\n",
    "                        margins_name='Total')\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista de nombres deptos para generar tabla en latex\n",
    "nomdep = ['Mvdeo.', 'Artigas', 'Can.', 'C. Largo', 'Colonia', 'Durazno',\n",
    "          'Flores', 'Florida', 'Lavalleja','Maldonado', 'Paysandú', 'R. Negro', 'Rivera',\n",
    "          'Rocha', 'Salto', 'San José', 'Soriano', 'Tacuarembó', 'T. y Tres']\n",
    "\n",
    "coddep = np.arange(1, 20, 1).tolist()\n",
    "\n",
    "# guarda tabla en latex\n",
    "# cabecera = datos_dpto.sort_values('DPTO')['NOMBRE'].to_list()\n",
    "# cabecera.append('Total')\n",
    "\n",
    "matrix_tex = matrix\n",
    "matrix_tex.rename(index=dict(zip(coddep, nomdep)), inplace=True)\n",
    "\n",
    "# setea ancho de columnas\n",
    "ancho = 'p{0.7cm}'\n",
    "colformato='l' + ancho * 20\n",
    "\n",
    "matrix_tex.to_latex(buf= \"tablas/matriz_orig_dest.tex\", bold_rows=False,\n",
    "                    column_format = colformato,\n",
    "                    caption= 'Matriz de movimientos entre departamentos (Censo INE 2011).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se contruye un conjunto de datos que contiene la siguiente información para cada díada de departamentos:\n",
    "- Los datos son los totales de personas que declaran haber vivido antes en el departamento de origen\n",
    "- La población total en origen y destino\n",
    "- El PBI en el departamento de destino y el logaritmo de dicho valor\n",
    "- La distancia entre cada centro medio de población y el logaritmo de dicho valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "ZmA9kwWBg5ng",
    "outputId": "400f9762-bb51-4d4c-f159-26ba4ba63a69"
   },
   "outputs": [],
   "source": [
    "# unimos todo en un dataframe de díadas\n",
    "df_agrupado = grupo.reset_index()\n",
    "\n",
    "# agrega codigo único\n",
    "df_agrupado.insert(0, 'cod', (df_agrupado['depto_origen'].astype(str)\n",
    "                   + df_agrupado['depto_destino'].astype(str).str.zfill(2)).astype(int))\n",
    "\n",
    "# recupera datos de otros dataframes\n",
    "cols = ['DPTO', 'NOMBRE', 'miles_de_pesos', 'poblacion']\n",
    "merge1 = pd.merge(df_agrupado, datos_dpto[cols],left_on='depto_origen', right_on='DPTO')\n",
    "merge2 = pd.merge(merge1, datos_dpto[cols], left_on='depto_destino', right_on='DPTO')\n",
    "merge3 = pd.merge(merge2, md[['cod', 'distancia']], on='cod')\n",
    "datos_diadas = merge3.drop(['DPTO_x', 'DPTO_y'], axis=1)\n",
    "\n",
    "# borra productos intermedios\n",
    "del(merge1, merge2, merge3)\n",
    "\n",
    "# renombra columnas\n",
    "dict_rename = {'NOMBRE_x': 'nom_depto_orig', 'NOMBRE_y': 'nom_depto_des',\n",
    "               'miles_de_pesos_x': 'pbi_origen', 'miles_de_pesos_y': 'pbi_destino',\n",
    "               'distancia': 'dist', 'poblacion_x': 'pob_origen',\n",
    "               'poblacion_y': 'pob_destino'}\n",
    "\n",
    "datos_diadas.rename(columns=dict_rename, inplace=True)\n",
    "\n",
    "# incorporamos el logaritmo del PBI departamental en destino\n",
    "datos_diadas = datos_diadas.assign(log_pbi_destino = lambda x: np.log(x['pbi_destino']))\n",
    "\n",
    "# incorporamos el logaritmo de las distancias entre díadas\n",
    "datos_diadas = datos_diadas.assign(log_dist = lambda x: np.log(x['dist']))\n",
    "\n",
    "# reordena variables\n",
    "order = ['cod', 'depto_origen', 'nom_depto_orig',\n",
    "         'depto_destino', 'nom_depto_des', 'personas_mig',\n",
    "         'pbi_origen', 'pob_origen', 'pbi_destino', 'pob_destino',\n",
    "         'dist', 'log_pbi_destino', 'log_dist']\n",
    "\n",
    "datos_diadas = datos_diadas[order]\n",
    "datos_diadas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guarda\n",
    "datos_diadas.to_csv('tablas/datos_diadas_2011.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define función para hacer lineas a partir de códigos origen-destino y una geografía conocida\n",
    "# fuente: https://github.com/danlewis85/UCL_CASA_Urban_Simulation/blob/master/Unconstrained%20Spatial%20Interaction%20Models.ipynb\n",
    "\n",
    "def _odline(orig, dest, geo, zonecode):\n",
    "    return LineString([deptos[geo[zonecode] == orig].centroid.values[0], geo[geo[zonecode] == dest].centroid.values[0]])\n",
    "\n",
    "# Makes a geodataframe of flows\n",
    "def odflow(flowdata, origin, destination, flow_value, geo, zonecode):\n",
    "    # First make all the lines\n",
    "    lines = flowdata.apply(lambda x: _odline(x[origin], x[destination], geo, zonecode), axis=1)\n",
    "    # Now get the series of flow values\n",
    "    flows = flowdata[[flow_value, origin, destination]]\n",
    "    # Now return a geodataframe\n",
    "    return gpd.GeoDataFrame(flows, geometry=lines, crs = geo.crs)\n",
    "\n",
    "# aplica función\n",
    "flows = odflow(datos_diadas,'depto_origen', 'depto_destino', 'personas_mig', deptos,'cod_ine')\n",
    "\n",
    "# guarda como geopaquete\n",
    "flows.to_file(\"capas/mig_recientes_2011.gpkg\", layer='flujos', driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_diadas.depto_origen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odflow(flowdata, origin, destination, flow_value, geo, zonecode):\n",
    "    # First make all the lines\n",
    "    lines = flowdata.apply(lambda x: _odline(x[origin], x[destination], geo, zonecode), axis=1)\n",
    "    # Now get the series of flow values\n",
    "    flows = flowdata[[flow_value, origin, destination]]\n",
    "    # Now return a geodataframe\n",
    "    return gpd.GeoDataFrame(flows, geometry=lines, crs = geo.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot de flujos\n",
    "f, ax = plt.subplots(1,figsize=(8,6))\n",
    "\n",
    "# apaga ejes\n",
    "plt.axis('off')\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.get_xaxis().set_visible(False)\n",
    "\n",
    "# capa de departamentos\n",
    "deptos.plot(color='w', edgecolor='silver' ,ax=ax)\n",
    "\n",
    "# máximo de flujos para escalado\n",
    "maxflow = float(max(flows['personas_mig']))\n",
    "\n",
    "# título\n",
    "# pl.title(\"Representación gráfica de las migraciones recientes\", size=10)\n",
    "\n",
    "# plotea flows, calcula ancha de línea con una función sobre 'personas_mig'\n",
    "flows.plot(linewidth = flows.apply(lambda x: (x['personas_mig']/maxflow)*10, axis=1),\n",
    "           color = 'red',ax=ax, label='Flujos entre departamentos', alpha=0.5)\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# referencias\n",
    "plt.legend(fontsize=9)\n",
    "\n",
    "plt.savefig('mapas_graficas/links_depto.pdf', bbox_inches='tight',\n",
    "            metadata = metadatos_figs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "colab_type": "code",
    "id": "dUb6ZM9duK49",
    "outputId": "8f6c58ef-1cea-41b4-f125-557bc49ba26a"
   },
   "outputs": [],
   "source": [
    "# Gráfico de flujos contra distancia\n",
    "f, ax = plt.subplots(1, figsize=(10,6))\n",
    "\n",
    "# plot de los puntos\n",
    "ax.scatter(datos_diadas['dist'], datos_diadas['personas_mig'], marker='.', color='k')\n",
    "\n",
    "# crea la linea roja\n",
    "xvals = np.geomspace(0.0055, datos_diadas['dist'].max(), 1000)\n",
    "yvals = np.power(xvals,-2.0)\n",
    "\n",
    "# la agrega al plot\n",
    "ax.plot(xvals, yvals, color='r')\n",
    "\n",
    "# hide spines\n",
    "[ax.spines[i].set_visible(False) for i in ['right', 'top', 'left', 'bottom']]\n",
    "\n",
    "# etiquetas\n",
    "ax.set_ylabel(\"Total de flujos\")\n",
    "ax.set_xlabel(\"Distancia (m)\")\n",
    "\n",
    "# se ven dos outlyers claramente, deben ser Mvdeo y Canelones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mismo gráfico sin Mvdeo.\n",
    "sin_mvo = datos_diadas[(datos_diadas['depto_origen'] > 1) & (datos_diadas['depto_destino'] > 1)]\n",
    "\n",
    "# Gráfico de flujos contra distancia\n",
    "f, ax = plt.subplots(1, figsize=(10,6))\n",
    "\n",
    "# plot de los puntos\n",
    "ax.scatter(sin_mvo['dist'], sin_mvo['personas_mig'], marker='.', color='k')\n",
    "\n",
    "# crea la linea roja\n",
    "xvals = np.geomspace(0.025, sin_mvo['dist'].max(), 100)\n",
    "yvals = np.power(xvals,-2.0)\n",
    "\n",
    "# la agrega al plot\n",
    "ax.plot(xvals, yvals, color='r')\n",
    "\n",
    "# Etiquetas\n",
    "ax.set_ylabel(\"Total de flujos\")\n",
    "ax.set_xlabel(\"Distancia (m)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gráfico de flujos contra población en el origen\n",
    "f, ax = plt.subplots(1, figsize=(10,6))\n",
    "\n",
    "# Plot data points\n",
    "ax.scatter(datos_diadas['pob_origen'], datos_diadas['personas_mig'], marker='.', color='k')\n",
    "\n",
    "# now work out the function y = x - basic linear slope with 0 origin.\n",
    "xvals = np.linspace(datos_diadas['pob_origen'].min(), datos_diadas['pob_origen'].max(), 100)\n",
    "yvals = np.power(xvals, 1.0)\n",
    "\n",
    "# Now add function line to plot\n",
    "ax.plot(xvals,yvals,color='r')\n",
    "\n",
    "# need to set the ylim to the domain of the origin pops, so we see the full line.\n",
    "ax.set_ylim(-5000, datos_diadas['pob_origen'].max()*1.05)\n",
    "\n",
    "# Add some labels\n",
    "ax.set_ylabel(\"Total de flujos\")\n",
    "ax.set_xlabel(\"Población en origen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot de PBI en destino contra personas migrantes\n",
    "f, ax = plt.subplots(1,figsize=(8,8))\n",
    "\n",
    "# Plot data points\n",
    "ax.scatter(datos_diadas['pbi_destino'], datos_diadas['personas_mig'], marker='.',color='k')\n",
    "\n",
    "# now work out the function y = x - basic linear slope with 0 origin.\n",
    "xvals = np.linspace(datos_diadas['pbi_destino'].min(), datos_diadas['pbi_destino'].max(), 100)\n",
    "yvals = np.power(xvals,1.0)\n",
    "\n",
    "# Now add function line to plot\n",
    "ax.plot(xvals,yvals,color='r')\n",
    "\n",
    "# need to set the ylim to the domain of the origin pops, so we see the full line.\n",
    "ax.set_ylim(-1000, datos_diadas['personas_mig'].max()*1.05)\n",
    "\n",
    "# Add some labels\n",
    "ax.set_ylabel(\"Total de flujos\")\n",
    "ax.set_xlabel(\"PBI en destino\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo restringido en origen\n",
    "\n",
    "1 $$T_{ij} = A_{i}O_{i}W_{j}^{\\alpha}d_{ij}^{-\\beta}$$\n",
    "\n",
    "dónde\n",
    "\n",
    "2 $$O_{i} = \\sum_{j}T_{ij}$$\n",
    "\n",
    "\n",
    "3 $$A_{i} = \\frac{1}{\\sum_{j}W_{j}^{\\alpha}d_{ij}^{-\\beta}}$$\n",
    "\n",
    "\n",
    "\n",
    "En el modelo restringido en origen $O_{i}$ no tiene parámetro dado que representa valores conocidos. $A_{i}$ es un factor de balance que refiere a cada origen $i$. Más específicamente $A_{i}$ permite que la suma de los valores estimados sea igual al total conocido $O_{i}$\n",
    "\n",
    "El modelo es re-especificado como un modelo de regresión de Poisson. Se asume una vinculación\n",
    "\n",
    "**We set about re-specifying the Production-Constrained model as a Poisson regression model in a similar way to how we did before. We need to take logs of the right-hand side of equation and assume that these are logarithmially linked to the Poisson distributed mean ($\\lambda_{ij}$) of the $T_{ij}$ variable. Equation 1 (above) then becomes:**\n",
    "\n",
    "\n",
    "4   $$ \\lambda_{ij} = \\exp( \\mu_{i} + \\alpha \\ln W_{j} - \\beta \\ln d_{ij} )$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "d6_Tr79nUp59",
    "outputId": "222cb649-971b-4a52-b2b3-6887c55bbeb9"
   },
   "outputs": [],
   "source": [
    "# el depto_origen se cambio a tipo texto para que no sea tomada como variable numérica por la regresión\n",
    "#  datos_diadas['depto_origen'] = datos_diadas.depto_origen.astype(str)\n",
    "\n",
    "# respalda el objeto para usarlo en el otro modelo\n",
    "dd=datos_diadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_diadas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados de la aplicación del modelo restringido en origen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "fnWKSI3s3NTZ",
    "outputId": "4247178e-8d02-4550-bd6a-97455d97d114"
   },
   "outputs": [],
   "source": [
    "# Here we specify a model with no intercept (given by the -1 in the formula)\n",
    "# In practice this means that all AiOis are estimated against an intercept of zero.\n",
    "# Including the interval would mean setting the first borough in OrigNewCode to the intercept\n",
    "# and interpreting all other categories in relation to that, which is less useful but would still work.\n",
    "formula = \"personas_mig ~ nom_depto_orig + log_pbi_destino + log_dist -1\"\n",
    "prodSim = smf.glm(formula=formula, data = datos_diadas, family = sm.families.Poisson()).fit()\n",
    "prodSim.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prodSim_latex = prodSim.summary().as_latex()\n",
    "f = open(\"tablas/prodSim.tex\", \"w\")\n",
    "f.write(prodSim_latex)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbNmxtmKOOhp"
   },
   "source": [
    "De los resultados se desprende un parámetro $\\alpha$ relacionado a la actractividad del destino de 0,8527.\n",
    "\n",
    "El parámetro $\\beta$ relativo al decaimiento por la distancia es de -0,7830\n",
    "\n",
    "El coeficiente para cada origen es el valor registrado $A_{i}O_{i}$ para ese origen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimaciones del modelo restringido en origen\n",
    "\n",
    "Los parámetros calculados se insertan en la ecuación nro. 4.\n",
    "\n",
    "$$ \\lambda_{ij} = \\exp( \\mu_{i} + 0,8527 ln W_{j}  + 0,7830 ln d_{ij} )$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some Oi and Dj columns in the dataframe and store row and column totals in them:\n",
    "# First get the origin sums and rename the column created\n",
    "O_i = datos_diadas.groupby('depto_origen')['personas_mig'].sum().to_frame()\n",
    "O_i.rename(columns = {'personas_mig':'O_i'}, inplace=True)\n",
    "\n",
    "# Now get the destination sums\n",
    "D_j = datos_diadas.groupby('depto_destino')['personas_mig'].sum().to_frame()\n",
    "D_j.rename(columns = {'personas_mig':'D_j'}, inplace=True)\n",
    "\n",
    "# Merge in O_i\n",
    "datos_diadas = datos_diadas.merge(O_i,left_on='depto_origen', right_index=True)\n",
    "\n",
    "# Merge in D_j\n",
    "datos_diadas = datos_diadas.merge(D_j,left_on='depto_destino', right_index=True)\n",
    "\n",
    "datos_diadas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recupera los parámetros del modelo\n",
    "mu_i = prodSim.params.to_frame()\n",
    "\n",
    "# elimina caractérres no numéricos para poder mergear\n",
    "mu_i.rename(index = dict(zip(mu_i.index[0:-2].values, mu_i.index[0:-2].str.replace(r'[^ ABCDEFGHIJKLMNÑOPQRSTUVWXYZ]','').values)),\n",
    "            inplace=True)\n",
    "\n",
    "# renombre columna\n",
    "mu_i.rename(columns = {0:'mu_i'}, inplace=True)\n",
    "\n",
    "# merge\n",
    "datos_diadas = datos_diadas.merge(mu_i, left_on='nom_depto_orig', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guarda parámetros estimados en objetos\n",
    "alpha = prodSim.params[19]\n",
    "beta  = prodSim.params[20]\n",
    "\n",
    "print(\"alfa (log PBI destino)= \" + str(alpha))\n",
    "print(\"beta (log distancia)= \" + str(beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genera estimación redondeada\n",
    "# esta es la estimación del modelo de la ecuación 4, imputando los parámetro alfa y beta calculados\n",
    "datos_diadas['prodsimest'] = np.round(np.exp(datos_diadas['mu_i']\n",
    "                                             + alpha * datos_diadas['log_pbi_destino']\n",
    "                                             + beta * datos_diadas['log_dist']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matriz de flujos estimada por el modelo\n",
    "datos_diadas['depto_origen'] = datos_diadas.depto_origen.astype(int)\n",
    "\n",
    "matrix_prodsim = pd.pivot_table(datos_diadas,\n",
    "                                values='prodsimest',\n",
    "                                index ='depto_origen',\n",
    "                                columns='depto_destino',\n",
    "                                fill_value=0,\n",
    "                                aggfunc=sum,\n",
    "                                margins=True,\n",
    "                                margins_name='Total')\n",
    "\n",
    "matrix_prodsim.Total = matrix_prodsim.Total.astype(int)\n",
    "\n",
    "matrix_prodsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_prodsim_tex = matrix_prodsim.rename(index=dict(zip(coddep, nomdep)))\n",
    "\n",
    "matrix_prodsim_tex.to_latex(buf= \"tablas/prodsim_matriz_orig_dest.tex\", bold_rows=False,\n",
    "                            column_format = colformato,  float_format=\"%.2f\",\n",
    "                            caption= 'Matriz de movimientos entre departamentos estimada mediante SIM restringido en origen.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede identificar la coincidencia de la matriz de los datos originales con la de los datos estimados en la columna de origen $O_{i}$, con leves diferencias producto del redondeo.\n",
    "\n",
    "$$\\sum_{j}T_{ij} = \\sum_{j}\\lambda_{ij} = O_{i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bondad de ajuste\n",
    "\n",
    "# define una función para calcular el R cuadrado\n",
    "def calcR2(obs, est):\n",
    "    return np.power(np.corrcoef(obs,est),2.0)[0][1]\n",
    "\n",
    "# define una función para calcula el error medio cuadrático\n",
    "def calcRMSE(obs,est):\n",
    "    return np.sqrt((np.power((obs - est),2.0)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd('**Bondad de ajuste del modelo restringido en origen**')\n",
    "\n",
    "printmd(\"$R²$ = \" + round(calcR2(datos_diadas['personas_mig'],datos_diadas['prodsimest']), 4).astype(str))\n",
    "\n",
    "printmd(\"RMSE = \" + round(calcRMSE(datos_diadas['personas_mig'],datos_diadas['prodsimest']), 4).astype(str))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de doble restricción\n",
    "\n",
    "5    $$ T_{ij} = A_{i}O_{i}B_{i}D_{j}d_{ij}^{-\\beta }$$\n",
    "\n",
    "dónde\n",
    "\n",
    "6 $$O_{i} = \\sum_{j}T_{ij}$$\n",
    "\n",
    "7 $$D_{j} = \\sum_{i}T_{ij}$$\n",
    "\n",
    "8 $$A_{i} = \\frac{1}{\\sum_{j}B_{j}D_{j}d_{ij}^{-\\beta}}$$\n",
    "\n",
    "9 $$B_{j} = \\frac{1}{\\sum_{j}A_{i}O_{j}d_{ij}^{-\\beta}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La dificultad es que $A_{i}$ depende de $B_{j}$ y viceversa. Pero se puede arrivar a un valor para ambos factores fijando el valor de $B$ inicialmente como 1, y luego iterando refinando el valor de cada uno hasta que sea estable (converjan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de restricción doble\n",
    "\n",
    "# recupera los datos del respaldo\n",
    "datos_diadas = dd\n",
    "# formula = \"personas_mig ~ nom_depto_orig + nom_depto_des + log_pbi_destino + log_dist -1\"\n",
    "\n",
    "# siguiendo a Dennett y la guía de R, cambiamos la fórmula, borrando el \"-1\" al final\n",
    "# es decir que se mantiene la intersección\n",
    "\n",
    "# The code below has changed a litte from the singly constrained models I have removed the ‘-1’\n",
    "# which means that an intercept will appear in the model again. This is not because I want an\n",
    "# intercept as it makes the origin and destination coefficients harder to interpret - reference categories\n",
    "# zones will appear and the coefficients will need to be compared with the intercept - rather the ‘-1’ cheat\n",
    "# for removing the intercept only works with one factor level - here we have two (origins and destinations).\n",
    "# For full details and an explanation for alternative ways for dealing with this, please visit\n",
    "# here - https://stats.stackexchange.com/questions/215779/removing-intercept-from-glm-for-multiple-factorial-predictors-only-works-for-fir - for ease, here we will just continue with the intercept.\n",
    "\n",
    "formula = \"personas_mig ~ nom_depto_orig + nom_depto_des + log_pbi_destino + log_dist\"\n",
    "\n",
    "doubSim = smf.glm(formula=formula, data = datos_diadas, family = sm.families.Poisson()).fit()\n",
    "doubSim.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guarda DF para enviar a Eugenia\n",
    "datos_diadas.head()\n",
    "datos_diadas.to_csv('tablas/datos_diadas.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doubSim_latex = doubSim.summary().as_latex()\n",
    "f = open(\"tablas/doubSim.tex\", \"w\")\n",
    "f.write(doubSim_latex)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recupera los valores estimados\n",
    "datos_diadas['doubsim_ajustado'] = np.round(doubSim.predict())\n",
    "\n",
    "datos_diadas['depto_origen'] = datos_diadas.depto_origen.astype(int)\n",
    "\n",
    "# matriz de los valores estimados\n",
    "matrix_doubsim = pd.pivot_table(datos_diadas,\n",
    "                                values='doubsim_ajustado',\n",
    "                                index ='depto_origen',\n",
    "                                columns='depto_destino',\n",
    "                                fill_value=0,\n",
    "                                aggfunc=sum,\n",
    "                                margins=True,\n",
    "                                margins_name='Total')\n",
    "\n",
    "matrix_doubsim.Total = matrix_doubsim.Total.astype(int)\n",
    "\n",
    "matrix_doubsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_doubsim_tex = matrix_doubsim.rename(index=dict(zip(coddep, nomdep)))\n",
    "\n",
    "matrix_doubsim_tex.to_latex(buf = \"tablas/doubsim_matriz_orig_dest.tex\",\n",
    "                            bold_rows = False,\n",
    "                            column_format = colformato,\n",
    "                            float_format =\"%.2f\",\n",
    "                            caption = 'Matriz de movimientos entre departamentos estimada mediante SIM de doble restricción.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar la igualdad de los valores originales $O_{i}$ y $D_{j}$, pero al igual que en el modelo de restricción en origen se producen leves direrencias que atrubuimos al redondeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd('**Bondad de ajuste del modelo de doble restricción**')\n",
    "\n",
    "printmd(\"$R²$ = \" + round(calcR2(datos_diadas['personas_mig'],  datos_diadas['doubsim_ajustado']), 4).astype(str))\n",
    "\n",
    "printmd(\"RMSE = \" + round(calcRMSE(datos_diadas['personas_mig'],datos_diadas['doubsim_ajustado']), 4).astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El coeficiente de determinación $R²$ mejora en comparación con resultante del modelo restringido en origen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a departure from Dennett, I've rewritten the algorithm as a function, which can then be called subject to the required parameters. In order for it to work it requires the following things:\n",
    "\n",
    "    pd - a pandas dataframe of origin-destination pairwise flows and associated data.\n",
    "    orig_field - the name of the dataframe field in pd that uniquely labels origin zones.\n",
    "    dest_field - the name of the dataframe field in pd that uniquely labels destination zones.\n",
    "    Oi_field - the name of the dataframe field that stores total flows from a given origin $i$\n",
    "    Dj_field - the name of the dataframe field that stores total flows to a given destination $j$\n",
    "    cij_field - the name of the dataframe field that stores the pairwise cost (e.g. distance) between $i$ and $j$\n",
    "    beta - a constant for the beta parameter you wish to use in the model\n",
    "    cost_function - a string representing the cost function, either 'power' or 'exponential'\n",
    "    Ainame - What you want to call the new field in pd that will hold $A&lt;/em&gt;{i}$ values, defaults to \"Ai_new\"\n",
    "    Bjname - What you want to call the new field in pd that will hold $B&lt;/em&gt;{j}$ values, defaults to \"Bj_new\"\n",
    "    converge - A threshold value at which a model can be said to have converged, the default of 0.001 seems to work fine.\n",
    "\n",
    "NB Remember that we calculated $O_{i}$ and $D_{j}$ earlier, they are simply the total flows by either origin or destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_diadas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the entropy maximising approach for a known beta.\n",
    "# Plug in the required values in this function to solve.\n",
    "\n",
    "def balance_doubly_constrained(pd, orig_field, dest_field,\n",
    "                               Oi_field, Dj_field, cij_field, beta, \n",
    "                               cost_function,\n",
    "                               Ai_name = \"Ai_new\", Bj_name = \"Bj_new\", converge=0.001):\n",
    "    # Define some variables\n",
    "    Oi = pd[[orig_field, Oi_field]]\n",
    "    Dj = pd[[dest_field,Dj_field]]\n",
    "    \n",
    "    if cost_function.lower() in ['power','pow']:\n",
    "        beta_cij = np.exp(beta * np.log(pd[cij_field]))\n",
    "    elif cost_function.lower() in ['exponential','exp']:\n",
    "        beta_cij = np.exp(beta * pd[cij_field])\n",
    "    else:\n",
    "        return \"Cost function not specified properly, use 'exp' or 'pow'\"\n",
    "    \n",
    "    # Create some helper variables\n",
    "    cnvg = 1\n",
    "    iteration = 0\n",
    "    \n",
    "    # Now iteratively rebalance the Ai and Bj terms until convergence\n",
    "    while cnvg > converge:\n",
    "        if iteration == 0:\n",
    "            # This first condition sets starting values for Ai and Bj\n",
    "            # NB sets starting value of Ai assuming Bj is a vector of 1s.\n",
    "            # We've already established beta_cij with the appropriate cost function, so...\n",
    "            Oi = Oi.assign(Ai = Dj[Dj_field] * beta_cij)\n",
    "            # Aggregate Ai and take inverse\n",
    "            Ai = 1.0/Oi.groupby(orig_field)['Ai'].sum().to_frame()\n",
    "            # Merge new Ais \n",
    "            Oi = Oi.merge(Ai,left_on = orig_field, right_index = True, suffixes = ('','_old'))\n",
    "            # Drop the temporary Ai field we created, leaving Ai_old\n",
    "            Oi.drop('Ai', axis=1, inplace=True)\n",
    "            \n",
    "            # Now set up Bjs using starting values of Ai\n",
    "            Dj = Dj.assign(Bj = Oi['Ai_old'] * Oi[Oi_field] * beta_cij)\n",
    "            # Aggregate Bj and take inverse\n",
    "            Bj = 1.0/Dj.groupby(dest_field)['Bj'].sum().to_frame()\n",
    "            # Merge new Bjs\n",
    "            Dj = Dj.merge(Bj,left_on = dest_field, right_index = True, suffixes = ('','_old'))\n",
    "            # Drop the temporary Bj field we created, leaving Bj_old\n",
    "            Dj.drop('Bj', axis=1, inplace=True)\n",
    "            \n",
    "            # Increment loop\n",
    "            iteration += 1\n",
    "        else:\n",
    "            # This bit is the iterated bit of the loop which refines the values of Ai and Bj\n",
    "            # First Ai\n",
    "            Oi['Ai'] = Dj['Bj_old'] * Dj[Dj_field] * beta_cij\n",
    "            # Aggregate Ai and take inverse\n",
    "            Ai = 1.0/Oi.groupby(orig_field)['Ai'].sum().to_frame()\n",
    "            # Drop temporary Ai\n",
    "            Oi.drop('Ai', axis=1, inplace=True)\n",
    "            # Merge new Ais \n",
    "            Oi = Oi.merge(Ai,left_on = orig_field, right_index = True)\n",
    "            # Calculate the difference between old and new Ais\n",
    "            Oi['diff'] = np.absolute((Oi['Ai_old'] - Oi['Ai'])/Oi['Ai_old'])\n",
    "            # Set new Ais to Ai_old\n",
    "            Oi['Ai_old'] = Oi['Ai']\n",
    "            # Drop the temporary Ai field we created, leaving Ai_old\n",
    "            Oi.drop('Ai', axis=1, inplace=True)\n",
    "            \n",
    "            # Then Bj\n",
    "            Dj['Bj'] = Oi['Ai_old'] * Oi[Oi_field] * beta_cij\n",
    "            # Aggregate Bj and take inverse\n",
    "            Bj = 1.0/Dj.groupby(dest_field)['Bj'].sum().to_frame()\n",
    "            # Drop temporary Bj\n",
    "            Dj.drop('Bj', axis=1, inplace=True)\n",
    "            # Merge new Bjs\n",
    "            Dj = Dj.merge(Bj,left_on = dest_field, right_index = True)\n",
    "            # Calculate the difference between old and new Bjs\n",
    "            Dj['diff'] = np.absolute((Dj['Bj_old'] - Dj['Bj'])/Dj['Bj_old'])\n",
    "            # Set new Bjs to Bj_old\n",
    "            Dj['Bj_old'] = Dj['Bj']\n",
    "            # Drop the temporary Bj field we created, leaving Bj_old\n",
    "            Dj.drop('Bj', axis=1, inplace=True)\n",
    "            \n",
    "            # Assign higher sum difference from Ai or Bj to cnvg\n",
    "            cnvg = np.maximum(Oi['diff'].sum(),Dj['diff'].sum())\n",
    "            \n",
    "            # Print and increment loop\n",
    "            print(\"Iteration:\", iteration)\n",
    "            iteration += 1\n",
    "\n",
    "    # When the while loop finishes add the computed Ai_old and Bj_old to the dataframe and return\n",
    "    pd[Ai_name] = Oi['Ai_old']\n",
    "    pd[Bj_name] = Dj['Bj_old']\n",
    "    return pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some Oi and Dj columns in the dataframe and store row and column totals in them:\n",
    "# First get the origin sums and rename the column created\n",
    "O_i = datos_diadas.groupby('depto_origen')['personas_mig'].sum().to_frame()\n",
    "O_i.rename(columns = {'personas_mig':'O_i'}, inplace=True)\n",
    "\n",
    "# Now get the destination sums\n",
    "D_j = datos_diadas.groupby('depto_destino')['personas_mig'].sum().to_frame()\n",
    "D_j.rename(columns = {'personas_mig':'D_j'}, inplace=True)\n",
    "\n",
    "# Merge in O_i\n",
    "datos_diadas = datos_diadas.merge(O_i,left_on='depto_origen', right_index=True)\n",
    "\n",
    "# Merge in D_j\n",
    "datos_diadas = datos_diadas.merge(D_j,left_on='depto_destino', right_index=True)\n",
    "\n",
    "datos_diadas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recupera el beta del logaritmo de la distancia del modelo anterior\n",
    "beta = doubSim.params[-1]\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recupera factores de balance\n",
    "datos_diadas = balance_doubly_constrained(datos_diadas, 'nom_depto_orig', 'nom_depto_des', 'O_i', 'D_j', 'log_dist', beta, \n",
    "                                          'pow', Ai_name = \"Ai_new\", Bj_name = \"Bj_new\", converge=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_diadas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now predict the model again using the new Ai and Dj fields.\n",
    "datos_diadas['SIM_est_pow'] = np.round(datos_diadas['O_i'] * datos_diadas['Ai_new'] * datos_diadas['D_j'] * datos_diadas['Bj_new'] * \n",
    "                                       np.exp(np.log(datos_diadas['log_dist'])*beta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the matrix\n",
    "pd.pivot_table(datos_diadas, values='SIM_est_pow', index ='depto_origen',\n",
    "               columns='depto_destino', fill_value=0, aggfunc=sum, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd('**Bondad de ajuste del modelo de doble restricción**')\n",
    "\n",
    "printmd(\"$R²$ = \" + round(calcR2(datos_diadas['personas_mig'],  datos_diadas['doubsim_ajustado']), 4).astype(str))\n",
    "\n",
    "printmd(\"RMSE = \" + round(calcRMSE(datos_diadas['personas_mig'],datos_diadas['doubsim_ajustado']), 4).astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jugar con modelación de distance decay\n",
    "# jugar con distancia en lugar de logaritmo\n",
    "# probar con algún modelo kitchen sink\n",
    "# graficas y algún mapa\n",
    "#!jupyter nbconvert --to markdown --no-input 02-metodologia.ipynb \n",
    "\n",
    "# graficar logaritmo de los flujos vs logaritmo de la distancia\n",
    "\n",
    "# probar paquete SPInt taylor oshan\n",
    "\n",
    "# ATENCIÓN!\n",
    "# Another thing to note is that the example we used here had quite neat data. You will almost certainly run into problems if you have sparse data or predictors with 0s in them. If this happens, then you might need to either drop some rows in your data (if populated with 0s) or substitute 0s for very small numbers, much less than 1, but greater than 0 (this is because you can’t take the log of 0). Taylor Oshan's SpInt implementation in Python uses a special Poisson regression approach that better handles sparse data structures.\n",
    "\n",
    "\n",
    "# modelar con binomial negativa\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPPDYSSpI6HjvyquGBWo+hx",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "0.0_data_wrangling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
